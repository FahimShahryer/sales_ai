# Akij Sales Intelligence System

A fully dynamic Multi-Agent RAG system for sales analytics powered by LLM and FAISS vector database.

## Features

- **Multi-Agent Architecture**: 4 specialized LLM agents working together
- **Zero Hardcoding**: All queries dynamically generated by LLM
- **RAG Integration**: FAISS vector database for business context
- **Smart Code Generation**: LLM generates pandas code on-the-fly
- **Interactive UI**: Two-column interface with chat + data table viewer
- **Dynamic Analysis**: Handles any sales query adaptively

## Architecture

### 4 Intelligent Agents:

1. **Query Understanding Agent** - Analyzes user intent and requirements
2. **RAG Agent** - Retrieves relevant business context from FAISS
3. **Data Retrieval Agent** - Generates and executes pandas code dynamically
4. **Master Synthesis Agent** - Combines everything into final answer

### Tech Stack:

- **Backend**: FastAPI, Python 3.12
- **LLM**: Google Gemini 2.0 Flash
- **Vector DB**: FAISS with HuggingFace embeddings
- **Data Processing**: Pandas, NumPy
- **Frontend**: Vanilla JavaScript, HTML5, CSS3

## Quick Start

### Local Development

1. **Clone Repository**
```bash
git clone https://github.com/YOUR_USERNAME/multi_agent_akij.git
cd multi_agent_akij
```

2. **Activate Virtual Environment**
```bash
# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Install Dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure Environment**
```bash
# Copy example env file
cp .env.example .env

# Edit .env and add your API keys
GEMINI_API_KEY=your_gemini_api_key_here
```

5. **Run Application**
```bash
python -m uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

6. **Access Application**
- Web UI: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Health Check: http://localhost:8000/api/health

## Deployment

### Deploy to Render.com

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed deployment instructions.

**Quick Deploy:**

1. Push code to GitHub
2. Create new Web Service on Render
3. Connect your repository
4. Add environment variables (GEMINI_API_KEY)
5. Deploy!

Your app will be live at: `https://your-app-name.onrender.com`

## Project Structure

```
multi_agent_akij/
├── backend/
│   ├── agents/                    # 4 LLM agents
│   │   ├── query_understanding_agent_v2.py
│   │   ├── rag_agent.py
│   │   ├── data_retrieval_agent_v2.py
│   │   └── master_synthesis_agent.py
│   ├── api/
│   │   └── routes_dynamic.py      # FastAPI endpoints
│   ├── orchestrator/
│   │   └── dynamic_orchestrator.py # Agent coordinator
│   ├── services/
│   │   ├── rag_service.py         # FAISS vector search
│   │   ├── data_service.py        # CSV data management
│   │   ├── llm_service.py         # Gemini API wrapper
│   │   └── code_executor.py       # Safe code execution
│   ├── static/                    # Frontend files
│   │   ├── index.html
│   │   ├── css/style.css
│   │   └── js/app.js
│   └── main.py                    # FastAPI app entry
├── data/                          # CSV datasets
│   ├── sales_transactions.csv
│   ├── product_master.csv
│   ├── branch_master.csv
│   ├── division_master.csv
│   └── customer_master.csv
├── faiss_index/                   # Vector database
├── requirements.txt
├── render.yaml                    # Render deployment config
├── .env.example
└── README.md
```

## How It Works

### Query Flow:

1. **User asks question** → Web UI
2. **API receives query** → `/api/chat` endpoint
3. **Orchestrator activates** → Coordinates all agents
4. **Agent 1** → Analyzes query intent
5. **Agent 2** → Retrieves business context from FAISS
6. **Agent 3** → Generates pandas code → Executes on data
7. **Agent 4** → Synthesizes final answer
8. **Response returned** → Natural language answer + data

### Example Queries:

- "What was total sales in 2024?"
- "Which products are trending upward?"
- "Should we open a new branch in Khulna?"
- "Compare Q3 vs Q4 revenue"
- "Forecast next month's sales"

## API Documentation

### Main Endpoint

**POST** `/api/chat`

```json
{
  "query": "What was total sales in 2024?"
}
```

**Response:**
```json
{
  "success": true,
  "answer": "Total sales in 2024 were 150.5M BDT...",
  "agent": "Data Analyst",
  "data": {...},
  "visualizations": []
}
```

### Other Endpoints

- **GET** `/api/health` - Health check
- **GET** `/api/table/{table_name}` - View raw data tables
- **GET** `/docs` - Interactive API documentation

## Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GEMINI_API_KEY` | Yes | Google Gemini API key |
| `OPENAI_API_KEY` | Optional | OpenAI API key |
| `LLM_PROVIDER` | No | `gemini` or `openai` (default: gemini) |
| `EMBEDDING_MODEL` | No | HuggingFace model name |

## Data Sources

The system analyzes 5 CSV datasets:

1. **Sales Transactions** - Transaction-level sales data
2. **Product Master** - Product catalog and details
3. **Branch Master** - Branch/location information
4. **Division Master** - Business division details
5. **Customer Master** - Customer information

## Features

- ✅ Natural language query interface
- ✅ Dynamic pandas code generation
- ✅ RAG-enhanced context retrieval
- ✅ Multi-agent collaboration
- ✅ Real-time data table viewer
- ✅ Sortable, searchable tables
- ✅ Zero hardcoded queries
- ✅ Fully adaptive system

## License

MIT License

## Author

Your Name

## Support

For issues and questions:
- Create an issue on GitHub
- Email: your.email@example.com

---

**Built with LLM + RAG + Multi-Agent Architecture**
